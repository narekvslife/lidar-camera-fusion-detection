{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32498148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "Loading nuScenes-lidarseg...\n",
      "32 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "34149 lidarseg,\n",
      "Done loading in 23.177 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 6.6 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import RandomRotation\n",
    "\n",
    "torch.multiprocessing.set_start_method('spawn')\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "from pyquaternion import Quaternion\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.preprocess import sample_to_rangeview, pcl_to_rangeview\n",
    "from src.utils import rotation_matrix\n",
    "from src.settings import DATASET_PATH, LABEL_NUMBER, RV_WIDTH, RV_HEIGHT, NUSCENES\n",
    "from src.datasets import NuscenesRangeViewDataset\n",
    "from src.models.lasernet import LaserNet\n",
    "from src.losses import LaserNetLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f45ae0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1147b71",
   "metadata": {},
   "source": [
    "## Training data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb87cf",
   "metadata": {},
   "source": [
    "- ___Classification___ task includes semantic segmentation. We predict class labels for each point (cell) in the Range View. If a cell in RV gets a class C, we extrapolate that all points (which fell into that cell during the transformation to RV) get the same label.\n",
    "- ___Regression___ task includes BB regression and mixture parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960503db",
   "metadata": {},
   "source": [
    "so a single training example consists of: \n",
    "\n",
    "- __$X$__: range_view image | __5 x W x H__\n",
    "\n",
    "\n",
    "- __$Y_{image}$:__ | __C x W x H__, where C - number of classes\n",
    "\n",
    "\n",
    "- __$Y_{bb}$:__ $\\{\\{b_{m,1}, b_{m,2}, b_{m,3}, b_{m,4}\\}, ..., \\}_m^M$ | __M x 4 x 2 x W x H__ | where M is the number of bounding boxes in the image, $b_{m, j} \\in R ^2$ is the absolute coordinate of $m$-th bounding box's $j$-th corner\n",
    "\n",
    "- __$Y_{logstd}$:__ $\\log(\\sigma)$ of the predicted bb coordinates| __scalar__\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea4c82",
   "metadata": {},
   "source": [
    "### DataSets, DataLoaders and Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f7f903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.26 ms, sys: 44 µs, total: 4.31 ms\n",
      "Wall time: 3.33 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/narekvslife/lidar-camera-fusion-detection/src/datasets.py:56: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.point_clouds_features = np.array(self.point_clouds_features)\n",
      "/home/narekvslife/lidar-camera-fusion-detection/src/datasets.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.point_clouds_labels = np.array(self.point_clouds_labels)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = NuscenesRangeViewDataset(data_root=DATASET_PATH, n=(0, 4))\n",
    "val_dataset = NuscenesRangeViewDataset(data_root=DATASET_PATH, n=(0, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f141738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# train_dataset = NuscenesRangeViewDataset(data_root=DATASET_PATH, n=(0, 8064))\n",
    "# val_dataset = NuscenesRangeViewDataset(data_root=DATASET_PATH, n=(8064, 9152))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2337d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=4, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751840a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b4ea39",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf9341",
   "metadata": {},
   "source": [
    "1. For each point in the image, we use the focal loss $L_{prob}$ to learn the class probabilities $\\{p_c\\}_{c=1}^C$. The classification loss for the entire image is defined as follows \n",
    "$$\n",
    "L_{cls} = {1 \\over P} \\sum_i{L_{prob, i}}\n",
    "$$ \n",
    "where P is the number of points in the image\n",
    "\n",
    "2. For each point on an object, we learn the parameters of the object’s mixture model by first identifying which component best matches the ground truth\n",
    "$$\n",
    "k^* = \\arg \\min_k || \\hat b_k − b^{gt} ||\n",
    "$$\n",
    "where $\\hat b_k$ is the k-th mean component of the mixture model\n",
    "and $b^{gt}$ is the corresponding ground truth bounding box.\n",
    "\n",
    "3. Afterwards, we update the parameters of the $k^{*}$ component\n",
    "$$\n",
    "L_{box} = \\sum_n {1 \\over \\hat \\sigma_{k^*}} | \\hat b_{n, k} − b^{gt}_n | + \\log{\\hat \\sigma_{k^*}}\n",
    "$$\n",
    "\n",
    "\n",
    "4. Next, we update the mixture weights $\\{α_k\\}^K_{k=1}$ again using the multi-class cross entropy loss $L_{mix}$, where the positive label corresponds to the $k^*$ component\n",
    "\n",
    "5. The regression loss for the entire image is defined as follows:\n",
    "$$\n",
    "L_{reg} = {{1 \\over N} \\sum_i{L_{box, i} + \\lambda L_{mix, i} \\over n_i}}\n",
    "$$\n",
    "where $L_{box, i}$ and $L_{mix, i}$ are the losses for the $i$-th point in the image which is on an object, $n_i$ is the total number of points that lie on the same object as $i$, $N$ is the total instances of objects in the image, and $\\lambda$ is the relative weighting of the two losses.\n",
    "\n",
    "6. Final loss is \n",
    "\n",
    "$$\n",
    "L = L_{reg} + L_{cls}\n",
    "$$\n",
    "\n",
    "___!NOTE! In this experiment we do not model a distribution of BB, which is equivalent to having a single mixture component or  K=1. Meaning: we do not have $L_{mix}$, we skip step 2___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf82fe4e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aad0bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        n_samples, n_classes, _, _ = inputs.shape\n",
    "        \n",
    "        targets = torch.argmax(targets, axis=1)\n",
    "        ce_loss = F.cross_entropy(inputs, targets.type(torch.long), reduction='none')  # == -log(pt)\n",
    "\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        \n",
    "        f_loss = torch.mean(self.alpha * (1 - pt) ** self.gamma * ce_loss, dim=(1, 2))\n",
    "        return f_loss\n",
    "\n",
    "class BoundingBoxRegressionLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BoundingBoxRegressionLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, log_std_preds, bb_loss_mask):\n",
    "        \"\"\"\n",
    "        inputs.shape == targets.shape == (N, 8, RV_WIDTH, RV_HEIGHT)\n",
    "\n",
    "        std_preds - predicted log standart deviations of bounding box corners\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(inputs.shape) == 0:\n",
    "            return torch.tensor(0)\n",
    "\n",
    "#         log_std_preds = log_std_preds.unsqueeze(1)\n",
    "#         one_over_sigma = torch.exp(-log_std_preds)\n",
    "\n",
    "#         box_losses = one_over_sigma * torch.abs(inputs - targets) + log_std_preds  # N x C x W x H\n",
    "        \n",
    "        box_losses = torch.nn.MSELoss(reduction='none')(inputs, targets)\n",
    "        \n",
    "        print(\"|0|\", torch.mean(box_losses,axis=1).shape)\n",
    "        print(\"|1|\", bb_loss_mask.shape)\n",
    "        print(\"|2|\", torch.mean(box_losses,axis=1)[bb_loss_mask].shape)\n",
    "        print(\"|3|\", (targets.permute(0, 2, 3, 1)[bb_loss_mask, :] == 0).any())\n",
    "        return torch.mean(torch.mean(box_losses,axis=1)[bb_loss_mask])\n",
    "\n",
    "class LaserNetLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, f_alpha=1, f_gamma=2, focal_loss_reduction='mean'):\n",
    "        super(LaserNetLoss, self).__init__()\n",
    "\n",
    "        self.focal_loss = FocalLoss(alpha=f_alpha, gamma=f_gamma, reduction=focal_loss_reduction)\n",
    "        self.bb_reg_loss = BoundingBoxRegressionLoss()\n",
    "        self.non_object_labels = [0, 24, 25, 26, 27, 28, 29, 30, 31]\n",
    "\n",
    "    def forward(self,\n",
    "                y_pointclass_preds, y_bb_preds, y_logstd_preds, \n",
    "                y_pointclass_target, y_bb_targets):\n",
    "        \n",
    "        point_target_labels = torch.argmax(y_pointclass_target, axis=1)\n",
    "        \n",
    "        L_point_cls = self.focal_loss(inputs=y_pointclass_preds,\n",
    "                                      targets=y_pointclass_target)\n",
    "        \n",
    "        # cell mask for points that have bb targets\n",
    "        bb_mask = torch.sum(y_bb_targets, axis=1) != 0\n",
    "\n",
    "        L_box_corners = self.bb_reg_loss(y_bb_preds,\n",
    "                                         y_bb_targets,\n",
    "                                         y_logstd_preds,\n",
    "                                         bb_mask)\n",
    "        \n",
    "        print('|point_classification_loss|', L_point_cls.mean().item(), '|bounding_box_loss|', L_box_corners.mean().item())\n",
    "\n",
    "        return torch.mean(L_point_cls + L_box_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1de15a83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|0| torch.Size([4, 128, 32])\n",
      "|1| torch.Size([4, 128, 32])\n",
      "|2| torch.Size([699])\n",
      "|3| tensor(False)\n",
      "|point_classification_loss| 3.8292064666748047 |bounding_box_loss| 11.120442390441895\n",
      "0 train_loss 14.9496488571167 accuracy 0.750732421875\n",
      "|0| torch.Size([4, 128, 32])\n",
      "|1| torch.Size([4, 128, 32])\n",
      "|2| torch.Size([699])\n",
      "|3| tensor(False)\n",
      "|point_classification_loss| 3.048405885696411 |bounding_box_loss| 11.560037612915039\n",
      "|0| torch.Size([4, 128, 32])\n",
      "|1| torch.Size([4, 128, 32])\n",
      "|2| torch.Size([699])\n",
      "|3| tensor(False)\n",
      "|point_classification_loss| 2.2995004653930664 |bounding_box_loss| 10.606685638427734\n",
      "|0| torch.Size([4, 128, 32])\n",
      "|1| torch.Size([4, 128, 32])\n",
      "|2| torch.Size([699])\n",
      "|3| tensor(False)\n",
      "|point_classification_loss| 1.8630638122558594 |bounding_box_loss| 10.485335350036621\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-1272f8efe439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_rv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_target_bbs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mbatch_pointclass_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_bb_param_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_log_stds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlasernet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_rv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lidar-camera-fusion-detection/src/datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;31m#             print(\"1\", pcl_features[:, :2].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mrange_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpcl_to_rangeview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcl_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcl_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mrange_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lidar-camera-fusion-detection/src/preprocess.py\u001b[0m in \u001b[0;36mpcl_to_rangeview\u001b[0;34m(pcl_features, pcl_labels)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# row numbers of points which have minimal distance in their groups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0midx_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ring_index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'azimuth_bin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj_with_exclusions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f, data)\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \"\"\"\n\u001b[0;32m--> 928\u001b[0;31m         \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;31m# group might be modified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mcurried\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mcurried\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0;31m# preserve the name so we can detect it when calling plot methods,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36midxmin\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \"\"\"\n\u001b[1;32m   2102\u001b[0m         \u001b[0mskipna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_argmin_with_skipna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2103\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanargmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanargmin\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \"\"\"\n\u001b[0;32m-> 1073\u001b[0;31m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value_typ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"+inf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_arg_null_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(values, skipna, fill_value, fill_value_typ, mask)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_get_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_maybe_get_mask\u001b[0;34m(values, skipna, mask)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mskipna\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mneeds_i8_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36misna\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \"\"\"\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_isna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36m_isna\u001b[0;34m(obj, inf_as_na)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCExtensionArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_isna_ndarraylike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minf_as_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minf_as_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36m_isna_ndarraylike\u001b[0;34m(obj, inf_as_na)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mis_string_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_isna_string_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minf_as_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minf_as_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mneeds_i8_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_string_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \"\"\"\n\u001b[1;32m    601\u001b[0m     \u001b[0;31m# TODO: gh-15585: consider making the checks stricter.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"O\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"S\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"U\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_excluded_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 2000\n",
    "\n",
    "lasernet = torch.nn.DataParallel(LaserNet(), device_ids=[0, 1])\n",
    "loss = LaserNetLoss()\n",
    "optimizer = torch.optim.Adam(lasernet.parameters(), lr=0.005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.95)\n",
    "\n",
    "\n",
    "lasernet.zero_grad()\n",
    "loss.zero_grad()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    for batch_rv, batch_labels, batch_target_bbs in train_dataloader:\n",
    "        \n",
    "        batch_pointclass_preds, batch_bb_param_preds, batch_log_stds = lasernet(x=batch_rv)\n",
    "        \n",
    "#         print(batch_pointclass_preds.shape, batch_bb_param_preds.shape, batch_log_stds.shape)\n",
    "        \n",
    "        L_train = loss(batch_pointclass_preds, batch_bb_param_preds, batch_log_stds, \n",
    "                       batch_labels, batch_target_bbs)\n",
    "        \n",
    "        lasernet.zero_grad()\n",
    "        \n",
    "        if torch.isnan(L_train):\n",
    "            break\n",
    "        L_train.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch_rv, batch_labels, batch_target_bbs in val_dataloader:\n",
    "            \n",
    "#             batch_pointclass_preds, batch_bb_param_preds = lasernet(x=batch_rv)\n",
    "\n",
    "#             L_val = loss(batch_pointclass_preds, batch_bb_param_preds, batch_labels, batch_target_bbs)\n",
    "        \n",
    "#             val_losses.append(L_val.item())\n",
    "\n",
    "#     torch.save(lasernet, f'lasernet-d{len(train_dataset)}-b64-e{epoch}-adam-lr002-sch095e1')\n",
    "\n",
    "    if torch.isnan(L_train):\n",
    "        break\n",
    "            \n",
    "    if epoch % 10 == 0:\n",
    "        batch_pointclass_pred_labels = torch.argmax(batch_pointclass_preds, axis=1)\n",
    "        batch_pointclass_labels = torch.argmax(batch_labels, axis=1)\n",
    "        \n",
    "        correct_preds = torch.sum(batch_pointclass_pred_labels == batch_pointclass_labels)\n",
    "        all_points = torch.sum(batch_pointclass_labels == batch_pointclass_labels)\n",
    "        accuracy = (correct_preds / all_points).item() * 100\n",
    "        \n",
    "        train_losses.append(L_train.item())\n",
    "        train_accs.append(accuracy)\n",
    "        \n",
    "        print(epoch, \"train_loss\", L_train.item(), \"accuracy\",  accuracy) #, \"val_loss\", L_val.item())\n",
    "    if epoch % 500 == 0:\n",
    "        lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ce03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28eab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd671ab",
   "metadata": {},
   "source": [
    "__[3] after transform fix | cross entropy and MSE | no log std | lr=0.001| gamma 097 every 100 epochs__\n",
    "\n",
    "|point_classification_loss| 0.25498661398887634 |bounding_box_loss| 85.12548828125\n",
    "\n",
    "1980 train_loss 85.60669708251953 val_loss 85.47611236572266\n",
    "\n",
    "\n",
    "bad boxes (even lines, not boxes) in the right places!\n",
    "\n",
    "---\n",
    "__[4] after transform fix | cross entropy and MSE | no log std | only non-zero boxes | lr=0.001| gamma 097 every 100 epochs____\n",
    "\n",
    "|point_classification_loss| 0.8824732303619385 |bounding_box_loss| 19.866052627563477\n",
    "\n",
    "870 train_loss 20.781124114990234 val_loss 20.748525619506836\n",
    "\n",
    "\n",
    "looks more like boxes, but in the wrong places as well, may fals positives near ego\n",
    "\n",
    "the further the object is, the thinner is it's bounding box\n",
    "\n",
    "---\n",
    "\n",
    "__[5] after transform fix | cross entropy and MSE | no log std | only non-zero boxes | lr=0.01| gamma 097 every 500 epochs__\n",
    "\n",
    "|point_classification_loss| 0.3059435784816742 |bounding_box_loss| 20.469608306884766\n",
    "\n",
    "870 train_loss 20.82895851135254 accuracy 89.617919921875\n",
    "\n",
    "---\n",
    "__[6] after transform fix| heads no elu | focal loss and log_std error | all boxes | lr=0.00005| gamma 095 every 200 epochs| std for each rv cell| mean by object__\n",
    "\n",
    "too slow, could ve made the lr bigger or the decrease slower\n",
    "\n",
    "|point_classification_loss| 0.2606876790523529 |bounding_box_loss| 1.9241503477096558\n",
    "\n",
    "\n",
    "1990 train_loss 2.184837818145752 accuracy 83.06884765625\n",
    "\n",
    "---\n",
    "\n",
    "__[7] after transform fix| heads no elu | focal loss and log_std error | all boxes | lr=0.001| gamma 095 every 500 epochs| std for each rv cell| mean by object__\n",
    "\n",
    "|point_classification_loss| 0.08178392797708511 |bounding_box_loss| 1.3698492050170898\n",
    "\n",
    "1990 train_loss 1.4516332149505615 accuracy 93.096923828125\n",
    "\n",
    "---\n",
    "\n",
    "__[8] after transform fix| heads no elu | focal loss and mse | selected boxes | lr=0.01| gamma 095 every 500 epochs| std for each rv cell| mean by object | 2k epochs__\n",
    "\n",
    "\n",
    "|point_classification_loss| 0.15576070547103882 |bounding_box_loss| 1.5972236394882202\n",
    "\n",
    "1380 train_loss 1.7529842853546143 accuracy 88.897705078125\n",
    "\n",
    "---\n",
    "\n",
    "__[9] fixed bb gradient mask| focal loss and mse| selected boxes| lr=0.01| gamma 095 every 500 epochs| std for each rv cell| 2k epochs__\n",
    "\n",
    "|point_classification_loss| 0.028342999517917633 |bounding_box_loss| 7.2635931968688965\n",
    "\n",
    "1130 train_loss 7.312100887298584 accuracy 97.137451171875\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0284d6d4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2a35311",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lasernet, 'lasernet9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b881518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasernet = torch.load('lasernet8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db51bad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 128, 32]), (32, 128, 32), (8, 128, 32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_object_labels = [0, 24, 25, 26, 27, 28, 29, 30, 31]\n",
    "\n",
    "with torch.no_grad():\n",
    "    pointclass_preds, bb_param_preds, _ = lasernet(x=batch_rv)\n",
    "\n",
    "pointclass_preds = pointclass_preds.detach().cpu().numpy()\n",
    "bb_corner_preds = bb_param_preds.detach().cpu().numpy()\n",
    "\n",
    "range_view_ex = batch_rv[1]\n",
    "class_predictions_ex = pointclass_preds[1]\n",
    "bb_corner_preds_ex = bb_corner_preds[1]\n",
    "\n",
    "range_view_ex.shape, class_predictions_ex.shape, bb_corner_preds_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3a237b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 32)\n"
     ]
    }
   ],
   "source": [
    "# Width x Height, max class labels of each cell\n",
    "class_pred_labels_ex = np.argmax(class_predictions_ex, axis=0)\n",
    "\n",
    "# sum([class_pred_labels_ex == nol for nol in non_object_labels]) == 0 128x32\n",
    "\n",
    "indices = np.array(np.nonzero(sum([class_pred_labels_ex == nol for nol in non_object_labels]) == 0)).T\n",
    "# unique widths and heights of cells wich are classified as objects\n",
    "\n",
    "# Classes x Width x Height, softmax probabilities of classes in each cell\n",
    "bb_class_probs_ex = torch.softmax(torch.Tensor(class_predictions_ex), dim=0).cpu().numpy()\n",
    "print(bb_class_probs_ex.shape)\n",
    "fig = go.Figure(data=[go.Scatter3d(x=range_view_ex[0].cpu().flatten(),\n",
    "                                   y=range_view_ex[1].cpu().flatten(),\n",
    "                                   z=np.zeros_like(range_view_ex[2].cpu().flatten()),\n",
    "                                   mode='markers',\n",
    "                                   marker=dict(size=2))])\n",
    "\n",
    "for w, h in indices:\n",
    "        # check model's certainty\n",
    "        class_prob = max(bb_class_probs_ex[:, w, h])\n",
    "        class_label = np.argmax(bb_class_probs_ex[:, w, h])\n",
    "\n",
    "        if class_prob > 0.5:\n",
    "            x = bb_corner_preds_ex[0::2, w, h]\n",
    "            y = bb_corner_preds_ex[1::2, w, h]\n",
    "            \n",
    "            fig.add_mesh3d(x=list(x), \n",
    "                           y=list(y),\n",
    "                           z=np.zeros_like(x))\n",
    "\n",
    "fig.write_html(\"kek9.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f770efd4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e81fcd",
   "metadata": {},
   "source": [
    "### Adding image information to the LaserNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaserNetPP(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685688b8",
   "metadata": {},
   "source": [
    "### Non-maximum supression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92098b42",
   "metadata": {},
   "source": [
    "- first we discard all boxes with it's class probability less than 0.6\n",
    "- then we select the most confident point and get rid of all boxes, that overlap with IoU >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89f366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
