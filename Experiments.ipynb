{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32498148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "Loading nuScenes-lidarseg...\n",
      "32 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "34149 lidarseg,\n",
      "Done loading in 23.609 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 6.7 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import RandomRotation\n",
    "\n",
    "torch.multiprocessing.set_start_method('spawn')\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "from pyquaternion import Quaternion\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.prepocess import sample_to_rangeview, pcl_to_rangeview\n",
    "from src.utils import rotation_matrix\n",
    "from src.settings import DATASET_PATH, LABEL_NUMBER, RV_WIDTH, RV_HEIGHT, NUSCENES\n",
    "from src.models.lasernet import LaserNet\n",
    "from src.losses import LaserNetLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f45ae0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1147b71",
   "metadata": {},
   "source": [
    "## Training data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb87cf",
   "metadata": {},
   "source": [
    "- ___Classification___ task includes semantic segmentation. We predict class labels for each point (cell) in the Range View. If a cell in RV gets a class C, we extrapolate that all points (which fell into that cell during the transformation to RV) get the same label.\n",
    "- ___Regression___ task includes BB regression and mixture parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960503db",
   "metadata": {},
   "source": [
    "so a single training example consists of: \n",
    "\n",
    "- __$X$__: range_view image | __5 x W x H__\n",
    "\n",
    "\n",
    "- __$Y_{image}$:__ | __C x W x H__, where C - number of classes\n",
    "\n",
    "\n",
    "- __$Y_{bb}$:__ $\\{\\{b_{m,1}, b_{m,2}, b_{m,3}, b_{m,4}\\}, ..., \\}_m^M$ | __M x 4 x 2 x W x H__ | where M is the number of bounding boxes in the image, $b_{m, j} \\in R ^2$ is the absolute coordinate of $m$-th bounding box's $j$-th corner\n",
    "\n",
    "- __$Y_{logstd}$:__ $\\log(\\sigma)$ of the predicted bb coordinates| __scalar__\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea4c82",
   "metadata": {},
   "source": [
    "### DataSets, DataLoaders and Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e97accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes import NuScenes\n",
    "from os.path import join\n",
    "\n",
    "class NuscenesDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_root, n: tuple=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): root NuScenes directory\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            \n",
    "            n - tuple with left and right index boundaries, in case we don't want to use all data\n",
    "        \"\"\"\n",
    "        assert len(n) == 2\n",
    "        self.data_root = data_root\n",
    "        self.nuscenes = NUSCENES\n",
    "\n",
    "        if n:\n",
    "            self.samples = self.nuscenes.sample[n[0]:n[1]]\n",
    "        else:\n",
    "            self.samples = self.nuscenes.sample\n",
    "            \n",
    "        # point_clouds_features will be of shape (N, M, 5), \n",
    "        # where N - number of samples, M - number of points in according sample's pointcloud\n",
    "        self.point_clouds_features = []\n",
    "        self.point_clouds_labels = []\n",
    "        \n",
    "        self.__set_point_clouds()\n",
    "            \n",
    "    def __set_point_clouds(self):\n",
    "\n",
    "        for sample in self.samples:\n",
    "            \n",
    "            sample_data_token = sample['data']['LIDAR_TOP']\n",
    "\n",
    "            my_sample_lidar_data = self.nuscenes.get('sample_data', sample_data_token)\n",
    "\n",
    "            lidarseg_labels_filename = join(self.data_root,\n",
    "                                            self.nuscenes.get('lidarseg', sample_data_token)['filename'])\n",
    "\n",
    "            # loading directly from files to perceive the ring_index information\n",
    "            points_raw = np.fromfile(self.data_root + my_sample_lidar_data[\"filename\"], dtype=np.float32).reshape((-1, 5))\n",
    "            point_labels = np.fromfile(lidarseg_labels_filename, dtype=np.uint8)\n",
    "            \n",
    "            self.point_clouds_features.append(points_raw)\n",
    "            self.point_clouds_labels.append(point_labels)\n",
    "            \n",
    "        self.point_clouds_features = np.array(self.point_clouds_features)\n",
    "        self.point_clouds_labels = np.array(self.point_clouds_labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def get_front_bb(self, sample: dict):\n",
    "        \"\"\"\n",
    "        Function computes and returns\n",
    "        An array of points points of a bounding box in sensor coordinates.\n",
    "        Each point is a (x, y) coordinate, each BB is 4 points\n",
    "\n",
    "        :param sample: nuscenes sample dictionary\n",
    "        :return: np.array of shape (N, 8, 3)\n",
    "        \"\"\"\n",
    "        my_sample_lidar_data = self.nuscenes.get('sample_data', sample['data']['LIDAR_TOP'])\n",
    "        sample_annotation = self.nuscenes.get_boxes(my_sample_lidar_data['token'])\n",
    "\n",
    "        ego_record = self.nuscenes.get('ego_pose', my_sample_lidar_data['ego_pose_token'])\n",
    "        cs_record = self.nuscenes.get('calibrated_sensor', my_sample_lidar_data['calibrated_sensor_token'])\n",
    "\n",
    "        # first step: transform from absolute to ego\n",
    "        ego_translation = -np.array(ego_record['translation'])\n",
    "\n",
    "        # second step: transform from ego to sensor\n",
    "        cs_translation = -np.array(cs_record['translation'])\n",
    "\n",
    "        corners = []\n",
    "        for box in sample_annotation:\n",
    "            box.translate(ego_translation)\n",
    "            box.rotate(Quaternion(ego_record['rotation']).inverse)\n",
    "\n",
    "            box.translate(cs_translation)\n",
    "            box.rotate(Quaternion(cs_record['rotation']).inverse)\n",
    "\n",
    "            # at this point bounding boxes are in sensor coordinate system\n",
    "            # now we want to exclude such BB that do not have their center\n",
    "            # lying in the front 90 degrees\n",
    "\n",
    "            if box.center[1] <= 0:\n",
    "                continue\n",
    "\n",
    "            box.center_azimuth = np.degrees(np.arctan(box.center[0] / box.center[1]))\n",
    "\n",
    "            # Transform front azimuth to be in range from 0 to 180\n",
    "            box.center_azimuth = 90 - box.center_azimuth\n",
    "            if not (45 < box.center_azimuth < 135):\n",
    "                continue\n",
    "\n",
    "            corners.append(box.bottom_corners())\n",
    "        \n",
    "        if len(corners) > 0:\n",
    "            return np.transpose(np.array(corners), (0, 2, 1))\n",
    "        else:\n",
    "            return np.zeros((1, 4, 3))\n",
    "    \n",
    "    def points_in_box(self, coordinates, bounding_box_corners):\n",
    "        \"\"\"\n",
    "            bounding_box_corners: bbc of a single bb\n",
    "            return a mask of whether points that are in the box\n",
    "        \"\"\"\n",
    "        coords_x = coordinates[0]\n",
    "        coords_y = coordinates[1]\n",
    "        \n",
    "        min_bb_x = bounding_box_corners[:, 0].min()\n",
    "        max_bb_x = bounding_box_corners[:, 0].max()\n",
    "        min_bb_y = bounding_box_corners[:, 1].min()\n",
    "        max_bb_y = bounding_box_corners[:, 1].max()\n",
    "\n",
    "        c1 = min_bb_x <= coords_x  # left_top/left_bottom.x <= coordinate.x\n",
    "        c2 = max_bb_x >= coords_x  # right_bottom/right_top.x >= coordinate.x\n",
    "        c3 = min_bb_y <= coords_y  # left/right_bottom.y <= coordinate.y\n",
    "        c4 = max_bb_y >= coords_y  # right_top/left_top.y >= coordinate.y\n",
    "\n",
    "        c = np.logical_and(np.logical_and(c1, c2),\n",
    "                           np.logical_and(c3, c4))\n",
    "        return c\n",
    "    \n",
    "    def get_bb_targets(self, idx, bounding_box_corners):\n",
    "        coordinates = self.point_clouds_features[idx][:2] \n",
    "    \n",
    "        for bb_c in bounding_box_corners:\n",
    "\n",
    "            if self.points_in_box(coordinates, bb_c).any():\n",
    "                return np.array(bb_c[:, :2])\n",
    "            \n",
    "            else:\n",
    "                return np.zeros_like(bb_c[:, :2])\n",
    "    \n",
    "    def __getitem__(self, idx, compute_boxes=True):\n",
    "        \"\"\"\n",
    "        compute_box will be set to False in child classes, so target boxes are computed after rotations\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        sample_idx = self.samples[idx]\n",
    "        pcl_features = self.point_clouds_features[idx]\n",
    "        pcl_labels = self.point_clouds_labels[idx]\n",
    "        \n",
    "        if compute_boxes:\n",
    "            front_bbs = self.get_front_bb(sample_idx)\n",
    "            target_bounding_boxes = self.get_bb_targets(idx, front_bbs)\n",
    "    \n",
    "            return pcl_features, pcl_labels, target_bounding_boxes\n",
    "        \n",
    "        else:\n",
    "            return pcl_features, pcl_labels, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf601d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NuscenesRangeViewDataset(NuscenesDataset):\n",
    "\n",
    "    def __init__(self, data_root, n=None):\n",
    "        super().__init__(data_root, n)\n",
    "        \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def get_bb_targets(self, range_view_coordinates, bounding_box_corners):\n",
    "        bbc_target = np.zeros((4, 2, RV_WIDTH, RV_HEIGHT))\n",
    "                \n",
    "        for bbc in bounding_box_corners:\n",
    "            point_mask = self.points_in_box(range_view_coordinates, bbc)\n",
    "            bbc_target[:, :, point_mask] = np.expand_dims(bbc, 2)\n",
    "            \n",
    "        return bbc_target.reshape((8, RV_WIDTH, RV_HEIGHT))\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        pcl_features, pcl_targets, _ = super().__getitem__(idx, compute_boxes=False)\n",
    "        \n",
    "        rotate_prob = np.random.uniform()\n",
    "        \n",
    "#         if rotate_prob > 0.5:\n",
    "#             rotation_angle_y = np.random.uniform(10, 90)\n",
    "\n",
    "#             rotation = RandomRotation((0, rotation_angle_y))\n",
    "#             print(\"0\", pcl_features[:, :2].shape)\n",
    "#             pcl_features[:, :2] = pcl_features[:, :2] @ rotation_matrix(torch.Tensor([rotation_angle_y])).cpu().numpy()\n",
    "#             print(\"1\", pcl_features[:, :2].shape)\n",
    "            \n",
    "        range_view, targets = pcl_to_rangeview(pcl_features, pcl_targets)\n",
    "        \n",
    "        range_view = range_view.transpose(2, 1, 0)\n",
    "        targets = targets.transpose(2, 1, 0)\n",
    "        \n",
    "        front_bbs = self.get_front_bb(self.samples[idx])[:, :, :2]  # N x 4 x 2 since we only need xy\n",
    "        target_bounding_boxes = self.get_bb_targets(range_view[:2], front_bbs)\n",
    "    \n",
    "        return torch.Tensor(range_view.copy()), torch.Tensor(targets.copy()), torch.Tensor(target_bounding_boxes.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49f7f903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 ms, sys: 57.5 ms, total: 66.5 ms\n",
      "Wall time: 64.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-79e4882f6273>:48: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.point_clouds_features = np.array(self.point_clouds_features)\n",
      "<ipython-input-9-79e4882f6273>:49: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.point_clouds_labels = np.array(self.point_clouds_labels)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = NuscenesRangeViewDataset(data_root=DATASET_PATH, n=(0, 128))\n",
    "val_dataset = NuscenesRangeViewDataset(data_root=DATASET_PATH, n=(100, 164))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed81ac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751840a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b4ea39",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf9341",
   "metadata": {},
   "source": [
    "1. For each point in the image, we use the focal loss $L_{prob}$ to learn the class probabilities $\\{p_c\\}_{c=1}^C$. The classification loss for the entire image is defined as follows \n",
    "$$\n",
    "L_{cls} = {1 \\over P} \\sum_i{L_{prob, i}}\n",
    "$$ \n",
    "where P is the number of points in the image\n",
    "\n",
    "2. For each point on an object, we learn the parameters of the object’s mixture model by first identifying which component best matches the ground truth\n",
    "$$\n",
    "k^* = \\arg \\min_k || \\hat b_k − b^{gt} ||\n",
    "$$\n",
    "where $\\hat b_k$ is the k-th mean component of the mixture model\n",
    "and $b^{gt}$ is the corresponding ground truth bounding box.\n",
    "\n",
    "3. Afterwards, we update the parameters of the $k^{*}$ component\n",
    "$$\n",
    "L_{box} = \\sum_n {1 \\over \\hat \\sigma_{k^*}} | \\hat b_{n, k} − b^{gt}_n | + \\log{\\hat \\sigma_{k^*}}\n",
    "$$\n",
    "\n",
    "\n",
    "4. Next, we update the mixture weights $\\{α_k\\}^K_{k=1}$ again using the multi-class cross entropy loss $L_{mix}$, where the positive label corresponds to the $k^*$ component\n",
    "\n",
    "5. The regression loss for the entire image is defined as follows:\n",
    "$$\n",
    "L_{reg} = {{1 \\over N} \\sum_i{L_{box, i} + \\lambda L_{mix, i} \\over n_i}}\n",
    "$$\n",
    "where $L_{box, i}$ and $L_{mix, i}$ are the losses for the $i$-th point in the image which is on an object, $n_i$ is the total number of points that lie on the same object as $i$, $N$ is the total instances of objects in the image, and $\\lambda$ is the relative weighting of the two losses.\n",
    "\n",
    "6. Final loss is \n",
    "\n",
    "$$\n",
    "L = L_{reg} + L_{cls}\n",
    "$$\n",
    "\n",
    "___!NOTE! In this experiment we do not model a distribution of BB, which is equivalent to having a single mixture component or  K=1. Meaning: we do not have $L_{mix}$, we skip step 2___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf82fe4e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1de15a83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:35<19:27:39, 35.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train_loss 6582125.5 val_loss 6690900.5 train_acc 0.9218928813934326 val_acc 0.9253486394882202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/2000 [01:10<19:27:09, 35.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 train_loss 5695357.5 val_loss 5520429.5 train_acc 0.9214316606521606 val_acc 0.9232984781265259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/2000 [01:45<19:24:38, 34.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 train_loss 3773771.75 val_loss 5654836.5 train_acc 0.9224770069122314 val_acc 0.9233952760696411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/2000 [02:20<19:24:13, 35.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 train_loss 4428862.5 val_loss 3997593.75 train_acc 0.9196770191192627 val_acc 0.9244595766067505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/2000 [02:54<19:23:17, 34.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 train_loss 3343447.75 val_loss 3091039.5 train_acc 0.921065092086792 val_acc 0.923688530921936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 6/2000 [03:29<19:22:34, 34.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 train_loss 2829292.0 val_loss 2552184.5 train_acc 0.9245278835296631 val_acc 0.923668622970581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 7/2000 [04:04<19:22:06, 34.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 train_loss 2346145.5 val_loss 1912703.625 train_acc 0.925176739692688 val_acc 0.9247094392776489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 8/2000 [04:40<19:22:54, 35.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 train_loss 1704073.125 val_loss 2142686.25 train_acc 0.9218039512634277 val_acc 0.9265470504760742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2000 [04:44<19:42:14, 35.61s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-02c85fea07f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mval_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_rv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_target_bbs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mbatch_pointclass_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_bb_param_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_log_std_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlasernet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_rv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-46f020edd7b2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#             print(\"1\", pcl_features[:, :2].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mrange_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpcl_to_rangeview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcl_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcl_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mrange_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lidar-camera-fusion-detection/src/prepocess.py\u001b[0m in \u001b[0;36mpcl_to_rangeview\u001b[0;34m(pcl_features, pcl_labels)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mpoints_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_min\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# class 0 is for noised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m         return self.obj._reindex_with_indexers(\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   4875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4876\u001b[0m             \u001b[0;31m# TODO: speed up on homogeneous DataFrame objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4877\u001b[0;31m             new_data = new_data.reindex_indexer(\n\u001b[0m\u001b[1;32m   4878\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4879\u001b[0m                 \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   1309\u001b[0m             )\n\u001b[1;32m   1310\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1311\u001b[0;31m             new_blocks = [\n\u001b[0m\u001b[1;32m   1312\u001b[0m                 blk.take_nd(\n\u001b[1;32m   1313\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1310\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m             new_blocks = [\n\u001b[0;32m-> 1312\u001b[0;31m                 blk.take_nd(\n\u001b[0m\u001b[1;32m   1313\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m                     \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1393\u001b[0m             \u001b[0mallow_fill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m         new_values = algos.take_nd(\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m   1699\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1701\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1702\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36mextract_array\u001b[0;34m(obj, extract_numpy)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \"\"\"\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCIndexClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.9/site-packages/pandas/core/dtypes/generic.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# https://github.com/python/mypy/issues/1006\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# error: 'classmethod' used with a non-method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_typ\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 2000\n",
    "\n",
    "lasernet = torch.nn.DataParallel(LaserNet(), device_ids=[0, 1])\n",
    "loss = LaserNetLoss(focal_loss_reduction='mean')\n",
    "optimizer = torch.optim.Adam(lasernet.parameters(), lr=0.000001)\n",
    "\n",
    "lasernet.zero_grad()\n",
    "loss.zero_grad()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    for batch_rv, batch_labels, batch_target_bbs in train_dataloader:\n",
    "        \n",
    "        batch_pointclass_preds, batch_bb_param_preds, batch_log_std_preds = lasernet(x=batch_rv)\n",
    "        \n",
    "        batch_logstd = torch.log(torch.std(batch_bb_param_preds, axis=(1, 2, 3)))        \n",
    "        \n",
    "        L_train = loss(batch_pointclass_preds, batch_bb_param_preds, batch_log_std_preds,\n",
    "                 batch_labels,           batch_target_bbs,     batch_logstd)\n",
    "        \n",
    "        train_losses.append(L_train.item())\n",
    "        \n",
    "        lasernet.zero_grad()\n",
    "        L_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_rv, batch_labels, batch_target_bbs in val_dataloader:\n",
    "            batch_pointclass_preds, batch_bb_param_preds, batch_log_std_preds = lasernet(x=batch_rv)\n",
    "            \n",
    "            L_val = loss(batch_pointclass_preds, batch_bb_param_preds, batch_log_std_preds,\n",
    "                         batch_labels,           batch_target_bbs,     batch_logstd)\n",
    "        \n",
    "            val_losses.append(L_val.item())\n",
    "            \n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(lasernet, f'lasernet-d10k-b64-e{epoch}-adam-lre6')\n",
    "        print(epoch, \"train_loss\", L_train.item(), \"val_loss\", L_val.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc73af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#         rv_example = batch_rv[7]\n",
    "#         bb_corners_targets_example = batch_target_bbs[7]\n",
    "        \n",
    "#         _, bb_w, bb_h = np.nonzero(bb_corners_targets_example).T\n",
    "#         bb_w, bb_h = np.unique(bb_w.cpu()), np.unique(bb_h.cpu())\n",
    "#         fig = go.Figure(data=[go.Scatter3d(x=rv_example[0].cpu().flatten(),\n",
    "#                                            y=rv_example[1].cpu().flatten(),\n",
    "#                                            z=np.zeros_like(rv_example[2].cpu().flatten()),\n",
    "#                                            mode='markers',\n",
    "#                                            marker=dict(size=2))])\n",
    "\n",
    "#         for wi in np.unique(bb_w):\n",
    "#             for he in np.unique(bb_h):\n",
    "#                 x = bb_corners_targets_example[::2, wi, he]\n",
    "#                 y = bb_corners_targets_example[1::2, wi, he]\n",
    "\n",
    "#                 fig.add_mesh3d(x=x.cpu(), \n",
    "#                                y=y.cpu(),\n",
    "#                                z=np.zeros_like(x.cpu()))\n",
    "\n",
    "#         fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3fa425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
